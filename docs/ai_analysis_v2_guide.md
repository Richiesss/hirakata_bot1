# AI分析v2: スマート分析機能ガイド

## 概要

**AI分析v2（スマート分析）** は、従来のBERTクラスタリングに代わる、LLMベースの意見分析機能です。市職員の方々が直感的に理解できるように設計されています。

## 🎯 主な改善点

### 従来の問題点
- ❌ 散布図が意味不明（点が並んでいるだけ）
- ❌ クラスタに名前がない（"Group 0"では内容が不明）
- ❌ 代表意見が最初の20文字（内容が把握できない）
- ❌ 優先度が見えない（どれから対応すべきか分からない）
- ❌ アクションに繋がらない（見て終わり）

### 新しいアプローチ
- ✅ **トピック名が自動生成**（例：「通学路の安全性」「公園の設備」）
- ✅ **要約文がある**（各トピックの内容を100文字で説明）
- ✅ **緊急度が明確**（緊急・高・中・低の4段階）
- ✅ **推奨アクションを提示**（具体的な対応案を3つまで提示）
- ✅ **キーワード表示**（トピックの特徴を一目で把握）

---

## 📊 分析の仕組み

### 処理フロー

```
意見データ（テキスト）
    ↓
【LLMでトピック抽出】
    ↓
「通学路の安全性」
「公園の設備」
「ゴミ問題」
「情報提供」
    ↓
【LLMで意見を分類】
    ↓
各トピックに意見を割り当て
    ↓
【LLMで要約・優先度判定】
    ↓
市職員向けダッシュボード
```

### 技術スタック

- **LLM**: Ollama (llama3.2)
- **言語**: Python 3.10+
- **フレームワーク**: Flask
- **主な機能**:
  - トピック自動抽出
  - 意見の自動分類
  - 要約生成
  - 優先度判定
  - 推奨アクション生成

---

## 🚀 使い方

### 1. 管理画面にアクセス

```
http://localhost:5001/admin/analysis
```

### 2. スマート分析を実行

- **分析スコープ**を選択:
  - 最新200件（デフォルト）
  - 最新1000件
  - インポートデータのみ
  - 全データ

- **「スマート分析 (新版)」ボタンをクリック**

### 3. 結果を確認

分析結果には以下が含まれます：

#### トピックカード
```
🟡 通学路の安全性 (7件)
緊急度: 高

📝 要約
〇〇交差点の信号が見づらく、特に朝の通学時間帯は
児童が危険にさらされています。白線も消えかけています。

🔑 キーワード
信号機, 横断歩道, 通学路

✅ 推奨アクション
1. 〇〇交差点の信号機を改善し、雨の日でも見やすくする
2. 通学路の白線を塗り直す
3. 定期的な安全点検を実施する

含まれる意見を見る (7件)
```

---

## 📝 ファイル構成

### 新規作成ファイル

| ファイル | 説明 |
|---------|------|
| `features/ai_analysis_v2.py` | スマート分析のメインロジック |
| `admin/templates/analysis_v2.html` | 新しいUI（市職員向け） |
| `test_analysis_v2.py` | テストスクリプト |
| `docs/ai_analysis_v2_guide.md` | このドキュメント |

### 修正ファイル

| ファイル | 変更内容 |
|---------|---------|
| `admin/admin_app.py` | スマート分析のルート追加 |
| `admin/templates/analysis.html` | 新版/旧版切り替えボタン追加 |

---

## 🧪 テスト方法

### 1. テストスクリプトを実行

```bash
cd /home/hirakata_bot1
python test_analysis_v2.py
```

### 2. 期待される出力

```
============================================================
AI分析v2 テスト実行
============================================================

対象意見数: 10件

✓ Ollamaサービスは利用可能です

分析を開始します...

[  5%] 意見データを準備中...
[ 10%] トピックを抽出中...
[ 50%] 意見をトピック別に分類中...
[ 70%] トピック 1/4 を分析中...
...
[100%] 分析完了！

============================================================
分析結果
============================================================

📊 全体サマリー:
   市民はインフラの状態や安全性、清掃、管理...

🔍 検出されたトピック数: 4
📝 分析対象意見数: 10件
```

---

## ⚙️ 設定・カスタマイズ

### トピック数の変更

`features/ai_analysis_v2.py` の `analyze_opinions()` メソッド:

```python
def analyze_opinions(
    self,
    opinions: List[Dict[str, Any]],
    max_topics: int = 7,  # ← ここを変更
    progress_callback=None
) -> Dict[str, Any]:
```

### LLMモデルの変更

`config.py`:

```python
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")  # ← ここを変更
```

推奨モデル:
- `llama3.2` (デフォルト、バランス型)
- `llama3.1:8b` (高速)
- `mixtral` (高精度)

---

## 🔍 比較：旧版 vs 新版

| 項目 | 旧版（BERT） | 新版（LLM） |
|------|-------------|------------|
| **ベクトル化** | BERT (768次元) | なし（直接LLM処理） |
| **クラスタリング** | K-Means | LLMベース分類 |
| **トピック名** | なし ("Group 0") | 自動生成 |
| **要約** | 最初の20文字 | LLMで100文字要約 |
| **優先度** | キーワードマッチ | LLMで判定 |
| **推奨アクション** | なし | LLMで3つ提示 |
| **可視化** | 散布図（分かりにくい） | カード形式（分かりやすい） |
| **処理時間** | 初回は遅い（モデルロード） | 中程度 |
| **精度** | 中 | 高 |
| **実用性** | 低 | 高 |

---

## 💡 使用例

### ケース1: 通学路の安全性問題

**入力意見（3件）:**
- 〇〇交差点の信号が見づらくて危険
- 横断歩道の白線が消えかけている
- 通学時間帯に車のスピードが速すぎる

**分析結果:**
```
🔴 通学路の安全性 (3件) - 緊急度: 高

要約:
〇〇交差点の信号が見づらく、横断歩道の白線も消えており、
通学時間帯の安全性が懸念されています。

推奨アクション:
1. 〇〇交差点の信号機を改善
2. 横断歩道の白線を塗り直す
3. 通学時間帯の速度規制を強化
```

### ケース2: 複数のトピックが混在

**入力意見（10件）:**
- 信号機の問題（3件）
- 公園の遊具（2件）
- ゴミ問題（3件）
- ホームページ（2件）

**分析結果:**
```
4つのトピックに自動分類:
1. 交通安全 (3件) - 緊急度: 高
2. 公園設備 (2件) - 緊急度: 中
3. 環境衛生 (3件) - 緊急度: 中
4. 情報提供 (2件) - 緊急度: 低
```

---

## 🚨 トラブルシューティング

### エラー: "Ollama service not available"

**原因**: Ollamaが起動していない

**解決方法**:
```bash
# Ollamaを起動
ollama serve

# 別のターミナルでモデルをダウンロード（初回のみ）
ollama pull llama3.2
```

### エラー: "Failed to extract topics"

**原因**: LLMの応答がJSON形式でない

**解決方法**:
- Ollamaのバージョンを確認: `ollama --version`
- モデルを再ダウンロード: `ollama pull llama3.2`
- `config.py`でモデルを変更

### 分析が遅い

**原因**: 大量データまたはCPU環境

**解決方法**:
- 分析スコープを「最新200件」に制限
- GPUを使用: Ollamaの設定を確認
- より小さいモデルを使用: `llama3.2:1b`

---

## 📈 今後の改善案

### 短期（実装済み）
- ✅ LLMベーストピック抽出
- ✅ 自動要約
- ✅ 優先度判定
- ✅ 推奨アクション生成

### 中期（検討中）
- [ ] トピック間の関連性分析
- [ ] 時系列トレンド分析
- [ ] 意見の感情分析（ポジ/ネガ）
- [ ] PDF出力（新版対応）

### 長期（構想）
- [ ] リアルタイム分析（意見投稿時に自動分類）
- [ ] 担当部署の自動割り振り
- [ ] 過去の対応事例の検索
- [ ] 議会資料の自動生成

---

## 🤝 フィードバック

新しいスマート分析について、ご意見・ご要望があればお知らせください。

**改善の視点:**
- UI/UXの使いやすさ
- 分析結果の精度
- 処理速度
- 追加機能の提案

---

## 📚 参考資料

- [Ollama公式ドキュメント](https://ollama.ai/docs)
- [Llama 3.2モデル情報](https://ollama.ai/library/llama3.2)
- [プロジェクトREADME](/home/hirakata_bot1/README.md)

---

**作成日**: 2025年12月9日
**バージョン**: 1.0
**担当**: AI分析システム開発チーム
